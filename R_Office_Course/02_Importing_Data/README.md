# Module 02: Importing & Exporting Data

## 1. The "Real World" CSV
Data is rarely perfect.
- **Skip Rows**: Metadata often lives in the first few lines.
- **No Header**: Sometimes columns just start.
- **Weird NA values**: Systems might use "-", "NULL", or "Unknown" for missing data.

```r
library(tidyverse)

# Scenario: File has 3 lines of description before the table starts.
# And uses "999" as a missing value code.
raw_data <- read_csv(
  "data/messy_report.csv", 
  skip = 3,                  # Skip first 3 lines
  col_names = TRUE,          # The 4th line is the header
  na = c("", "NA", "999", "-") # Treat all these as Missing Data
)
```

## 2. Excel Hell
Excel files often have multiple header rows or merged cells. R hates merged cells.
Tip: `read_excel` reads the *value* of the top-left cell of a merge, and `NA` for the rest. You might need `fill()` from `tidyr` to fix this.

```r
library(readxl)
library(tidyr)

# Reading a specific range to avoid junk data
budget <- read_excel(
  "finance.xlsx", 
  sheet = "Q1", 
  range = "A5:F100" # Only read the table part
)
```

## 3. Exporting for Non-R Users
Your boss wants Excel, not an R Object.

```r
# Install if needed: install.packages("writexl")
library(writexl)

# Exporting a list of dataframes as a multi-sheet Excel file
# (Replace these with your actual dataframes)
sheets <- list(
  "Summary" = summary_df,
  "Raw Data" = raw_df,
  "Errors" = error_log
)

write_xlsx(sheets, "Weekly_Report.xlsx")
```

## Practice
1.  Create a CSV file with a comment in line 1 (`# Report generated by System X`) and data starting in line 2.
2.  Use `read_csv` with the `comment = "#"` argument or `skip = 1`.

---
*Next: [Module 03: Data Structures](../03_Data_Structures/README.md)*
